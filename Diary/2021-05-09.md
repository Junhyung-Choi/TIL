# 2021-05-09

- What I learned: 
  - Linear Algebra
    - Approximation: The problem of finding A so that the difference between the vector made of Ax and the actual b is the smallest
      - Least Square: Situation in which the sum of the minimum distance between the vector space and each vector b is minimum  
        - Minimun Distance: Distance when vector space and vector b meet vertically
    - Orthogonal(perpendicualr - regulary on 2nd, 3rd dimention):Situation when vector space and vector meet vertically
      - How can you determine whether vectors are orthogonal?
        - Innder Product or Dot product is 0 when vetors meet vertically
      - Orthogonal Complements: All vectors orthogonal to $R^{n}$space $W$ are called the orthogonal complements of $W$.
        - $W^{\perp}$
        - All vectors on $W^{\perp}$ meet vertically to all vectors on $W$.
        - $W^{\perp}$ is subspace of $R^{n}$
      - Orthogonal Set
        - If both random vectors of $S$ are orthogonal, then $S$ is called the orthogonal set.
        - If the set of non-zero vectors is an orthogonal set, it is linearly independent
        - Orthogonal Basis
          - If the basis set $S$ of $R^{n}$ is an orthogonal set, it is called an Orthogonal Basis.
          - For subspace $W$ of $R^{n}$, if $\{u_1,u_2,\cdots,u_p\}$ is an orthogonal basis, then the following holds for $y = c_{1}u_{1} + \cdots + c_{p}u_{p}$.
            - ## $c_{j} = {y \cdot u_{j} \over u_{j} \cdot u_{j}}$
        - Orthogonal Projection
            - Vector generated when a vector is projected onto a vector (space)
            - ${\hat {y}}$ or $\mathrm{proj}_{W}y$
            - Orthogonal Component: $z = y - \hat y$
        - Orthonormal Set
          - If it is a unit vector set and an orthogonal set, it is called a Orthonormal Set.
          - Orthonormal Basis: When there is a subspace $W$ spanned by a Orthonormal Set, this orthonormal set is called the Orthonormal Basis of $W$
          - Theorem 1
            - If $m \times n$ matrix $U$'s columns are Orthonormal Set, It is neccessary and sufficient conditions with followings. 
              - $U^{T}U = I$
          - Theorem 2
            - If $m \times n$ matrix $U$'s columns are Orthonormal Set, the following holds for $x,y$ on $R^n$
              - $||Ux|| = ||x||$
                - $\sqrt {Ux \cdot Ux} = \sqrt {(Ux)^{T} \cdot Ux} = \sqrt {x^{T}U^{T}Ux} = \sqrt{x^{T}x} = \sqrt{x \cdot x}$ 
              - $(Ux) \cdot (Uy) = x \cdot y$
              - $(Ux) \cdot (Uy) = 0 \text{ if and only if } x \cdot y = 0$
- What was interesting:
  - Watched money game. So interesting 
- What I regret: 
  - Slept too late,